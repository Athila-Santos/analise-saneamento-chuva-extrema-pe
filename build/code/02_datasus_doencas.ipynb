{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1F1x7f9NFhrb3KFZT4WdqZtPPVW2tQPBn","authorship_tag":"ABX9TyPsCxQg7USLcTVRB8/CYOze"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import os # Biblioteca para interagir com o sistema operacional\n","import re"],"metadata":{"id":"J_HWKietg8In","executionInfo":{"status":"ok","timestamp":1754334707322,"user_tz":180,"elapsed":4,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ---\n","# Passo 1: Definir o caminho para a pasta com os dados brutos\n","caminho_dados_brutos = '/content/drive/MyDrive/02 - Economia (UFPE)/2025.1/Tópicos de Macro (Economia do clima)/analise-saneamento-chuva-extrema-pe/build/input/doencas-datasus/'\n","\n","# Lista para armazenar os DataFrames de cada doença processada\n","lista_dfs_doencas = []\n","\n","print(\"Iniciando processamento dos arquivos do DATASUS...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVLXFi7Og-Cj","executionInfo":{"status":"ok","timestamp":1754334707334,"user_tz":180,"elapsed":9,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"677669ba-4b77-42f1-e961-70066a00ca50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Iniciando processamento dos arquivos do DATASUS...\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rQkHUH7e285","executionInfo":{"status":"ok","timestamp":1754334713111,"user_tz":180,"elapsed":5774,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"12007a96-6dff-4460-9e04-2a7e7f7344c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Lendo o arquivo: sinanwin_cnv_leptope14474145_4_61_174.csv\n","    -> Arquivo do tipo 'sinanwin'. Pulando 4 linhas.\n","    -> sinanwin_cnv_leptope14474145_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinanwin_cnv_denguepe15062545_4_61_174.csv\n","    -> Arquivo do tipo 'sinanwin'. Pulando 4 linhas.\n","    -> sinanwin_cnv_denguepe15062545_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinanwin_cnv_esquistope14591445_4_61_174.csv\n","    -> Arquivo do tipo 'sinanwin'. Pulando 4 linhas.\n","    -> sinanwin_cnv_esquistope14591445_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinanwin_cnv_febretifoidepe14573145_4_61_174.csv\n","    -> Arquivo do tipo 'sinanwin'. Pulando 4 linhas.\n","    -> sinanwin_cnv_febretifoidepe14573145_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinanwin_cnv_hepape14553745_4_61_174.csv\n","    -> Arquivo do tipo 'sinanwin'. Pulando 4 linhas.\n","    -> sinanwin_cnv_hepape14553745_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_leptope15133245_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_leptope15133245_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_febretifoidepe15194145_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_febretifoidepe15194145_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_denguepe15244145_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_denguepe15244145_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_denguebpe15304645_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_denguebpe15304645_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_chikunpe15332345_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_chikunpe15332345_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_zikape15351545_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_zikape15351545_4_61_174.csv processado com sucesso.\n","  Lendo o arquivo: sinannet_cnv_esquistope15390345_4_61_174.csv\n","    -> Arquivo do tipo 'sinannet'. Pulando 5 linhas.\n","    -> sinannet_cnv_esquistope15390345_4_61_174.csv processado com sucesso.\n"]}],"source":["# Passo 2: Loop para processar cada arquivo CSV na pasta\n","for filename in os.listdir(caminho_dados_brutos):\n","    if filename.endswith('.csv'):\n","        caminho_completo = os.path.join(caminho_dados_brutos, filename)\n","        print(f\"  Lendo o arquivo: {filename}\")\n","\n","        # Pega a terceira parte do nome do arquivo, ex: 'leptope14474145'\n","        parte_doenca = filename.split('_')[2]\n","        # Usa regex para extrair apenas as letras do início da string\n","        # e remove 'pe' e 'b' para padronizar\n","        match = re.search(r'([a-zA-Z]+)', parte_doenca)\n","        if match:\n","            nome_doenca = match.group(1).replace('pe', '').replace('dengueb', 'dengue')\n","\n","        try:\n","            # ---\n","            # *** LÓGICA CONDICIONAL ADICIONADA AQUI ***\n","            # Se o arquivo for do 'sinannet', pulamos 5 linhas. Caso contrário, pulamos 4.\n","            if 'sinannet' in filename:\n","                linhas_a_pular = 5\n","            else: # para 'sinanwin' e qualquer outro\n","                linhas_a_pular = 4\n","\n","            print(f\"    -> Arquivo do tipo '{'sinannet' if 'sinannet' in filename else 'sinanwin'}'. Pulando {linhas_a_pular} linhas.\")\n","\n","            df_raw = pd.read_csv(\n","                caminho_completo,\n","                encoding='latin-1',\n","                sep=';',\n","                skiprows=linhas_a_pular, # Usando a variável que definimos\n","                skipfooter=3,\n","                engine='python',\n","                decimal=','\n","            )\n","\n","            # ---\n","            # Passo 3: Limpeza da coluna de municípios (com Regex, que já é robusto)\n","            coluna_municipio_raw_nome = df_raw.columns[0]\n","            df_raw.rename(columns={coluna_municipio_raw_nome: 'municipio_raw'}, inplace=True)\n","\n","            df_raw['cod_municipio_6dig'] = df_raw['municipio_raw'].str.extract(r'(\\d{6})', expand=False)\n","            df_raw['nome_municipio'] = df_raw['municipio_raw'].str.replace(r'^\\d{6}\\s*', '', regex=True)\n","\n","            df_raw.drop(columns=['municipio_raw'], inplace=True)\n","            df_raw.dropna(subset=['cod_municipio_6dig'], inplace=True)\n","\n","            # ---\n","            # Passo 4: Transpor os dados (de formato largo para longo)\n","            df_long = pd.melt(\n","                df_raw,\n","                id_vars=['cod_municipio_6dig', 'nome_municipio'],\n","                var_name='ano',\n","                value_name='casos_notificados'\n","            )\n","\n","            df_long['doenca'] = nome_doenca\n","            lista_dfs_doencas.append(df_long)\n","            print(f\"    -> {filename} processado com sucesso.\")\n","\n","        except Exception as e:\n","            print(f\"    -> ERRO ao processar o arquivo {filename}: {e}\")"]},{"cell_type":"code","source":["# ---\n","# Passo 5: Concatenar todos os dataframes de doenças em um único\n","print(\"\\nConcatenando todos os dados de saúde...\")\n","df_saude_completo = pd.concat(lista_dfs_doencas, ignore_index=True)\n","\n","# Limpeza final\n","df_saude_completo['ano'] = pd.to_numeric(df_saude_completo['ano'], errors='coerce')\n","df_saude_completo.dropna(subset=['cod_municipio_6dig', 'ano'], inplace=True)\n","df_saude_completo['cod_municipio_6dig'] = df_saude_completo['cod_municipio_6dig'].astype(int)\n","df_saude_completo['ano'] = df_saude_completo['ano'].astype(int)\n","\n","print(\"\\n--- Processamento de Saúde Concluído! ---\")\n","print(\"Amostra da base de dados de saúde final:\")\n","print(df_saude_completo.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xVxBpOmhb-6","executionInfo":{"status":"ok","timestamp":1754334713154,"user_tz":180,"elapsed":25,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"62fef51f-8fce-471a-e353-0284a44570d9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Concatenando todos os dados de saúde...\n","\n","--- Processamento de Saúde Concluído! ---\n","Amostra da base de dados de saúde final:\n","   cod_municipio_6dig nome_municipio   ano casos_notificados doenca\n","0              260005   ABREU E LIMA  2001                 7  lepto\n","1              260030      AGRESTINA  2001                 -  lepto\n","2              260040     AGUA PRETA  2001                 -  lepto\n","3              260050    AGUAS BELAS  2001                 -  lepto\n","4              260070        ALIANCA  2001                 1  lepto\n"]}]},{"cell_type":"code","source":["print(\"--- Iniciando Limpeza Final e Balanceamento do Painel ---\")\n","\n","# ---\n","# ETAPA 1: Corrigir a coluna 'casos_notificados'\n","# ---\n","print(\"\\nPasso 1: Substituindo '-' por 0 e convertendo para inteiro...\")\n","\n","# Substituir o caractere '-' pelo número 0\n","df_saude_completo['casos_notificados'] = df_saude_completo['casos_notificados'].replace('-', 0)\n","\n","# Converter a coluna para um tipo numérico (float primeiro para lidar com possíveis NaNs)\n","df_saude_completo['casos_notificados'] = pd.to_numeric(df_saude_completo['casos_notificados'], errors='coerce')\n","\n","# Preencher quaisquer outros valores nulos que possam ter surgido\n","df_saude_completo['casos_notificados'] = df_saude_completo['casos_notificados'].fillna(0)\n","\n","# Finalmente, converter para inteiro (int)\n","df_saude_completo['casos_notificados'] = df_saude_completo['casos_notificados'].astype(int)\n","\n","print(\"Coluna 'casos_notificados' limpa e convertida para inteiro.\")\n","print(df_saude_completo.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9YNIcsmlVxW","executionInfo":{"status":"ok","timestamp":1754334713192,"user_tz":180,"elapsed":34,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"4533cb6d-0679-40a7-81c7-e8e928d56e24"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Iniciando Limpeza Final e Balanceamento do Painel ---\n","\n","Passo 1: Substituindo '-' por 0 e convertendo para inteiro...\n","Coluna 'casos_notificados' limpa e convertida para inteiro.\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 18242 entries, 0 to 19853\n","Data columns (total 5 columns):\n"," #   Column              Non-Null Count  Dtype \n","---  ------              --------------  ----- \n"," 0   cod_municipio_6dig  18242 non-null  int64 \n"," 1   nome_municipio      18242 non-null  object\n"," 2   ano                 18242 non-null  int64 \n"," 3   casos_notificados   18242 non-null  int64 \n"," 4   doenca              18242 non-null  object\n","dtypes: int64(3), object(2)\n","memory usage: 855.1+ KB\n","None\n"]}]},{"cell_type":"code","source":["# ---\n","# ETAPA 2: Criar um painel balanceado (a sua estratégia para linhas vazias)\n","# ---\n","print(\"\\nPasso 2: Criando um painel balanceado para incluir observações de 'zero casos'...\")\n","\n","# A. Criar a lista completa de todas as entidades do seu painel\n","anos = range(2002, 2022) # Seu período de interesse\n","municipios_unicos = df_saude_completo[['cod_municipio_6dig', 'nome_municipio']].drop_duplicates()\n","doencas_unicas = df_saude_completo['doenca'].unique()\n","\n","# B. Criar o \"molde\" ou \"scaffold\" com todas as combinações possíveis\n","# Usando pd.MultiIndex.from_product para criar todas as combinações\n","idx = pd.MultiIndex.from_product([anos, municipios_unicos['cod_municipio_6dig'], doencas_unicas],\n","                                 names=['ano', 'cod_municipio_6dig', 'doenca'])\n","painel_completo = pd.DataFrame(index=idx).reset_index()\n","\n","# Adicionar o nome do município de volta ao molde\n","# Criar um dicionário de mapeamento: codigo -> nome\n","mapa_nomes = municipios_unicos.set_index('cod_municipio_6dig')['nome_municipio']\n","painel_completo['nome_municipio'] = painel_completo['cod_municipio_6dig'].map(mapa_nomes)\n","\n","\n","# C. Fazer um 'left merge' dos seus dados de saúde no molde completo\n","# O molde está à esquerda, garantindo que todas as combinações de ano/município/doença sejam mantidas\n","df_final_balanceado = pd.merge(\n","    painel_completo,\n","    df_saude_completo,\n","    on=['ano', 'cod_municipio_6dig', 'doenca', 'nome_municipio'],\n","    how='left'\n",")\n","\n","# D. Preencher os valores vazios (NaN) com zero\n","# As linhas que existiam no molde mas não nos seus dados são os casos de \"zero ocorrências\"\n","df_final_balanceado['casos_notificados'] = df_final_balanceado['casos_notificados'].fillna(0)\n","\n","# Converter a coluna para inteiro novamente, pois o merge pode ter reintroduzido floats\n","df_final_balanceado['casos_notificados'] = df_final_balanceado['casos_notificados'].astype(int)\n","\n","print(\"\\n--- Painel Balanceado Concluído! ---\")\n","print(f\"Número de linhas original: {len(df_saude_completo)}\")\n","print(f\"Número de linhas no painel balanceado: {len(df_final_balanceado)}\")\n","\n","print(\"\\nAmostra da base de dados final e balanceada:\")\n","# Vamos ver um exemplo para um município/doença e ver se todos os anos estão presentes\n","print(df_final_balanceado[\n","    (df_final_balanceado['cod_municipio_6dig'] == 260030) & # Agrestina\n","    (df_final_balanceado['doenca'] == 'lepto')\n","].head())\n","\n","df_final_balanceado.to_csv('/content/drive/MyDrive/02 - Economia (UFPE)/2025.1/Tópicos de Macro (Economia do clima)/analise-saneamento-chuva-extrema-pe/build/output/doencas_pe_2001_2021.csv', index=False, encoding='utf-8-sig')"],"metadata":{"id":"jSdPzB9qofY_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754334713646,"user_tz":180,"elapsed":438,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"c5c72c92-b17b-4bbd-ebef-aabf051716d9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Passo 2: Criando um painel balanceado para incluir observações de 'zero casos'...\n","\n","--- Painel Balanceado Concluído! ---\n","Número de linhas original: 18242\n","Número de linhas no painel balanceado: 27195\n","\n","Amostra da base de dados final e balanceada:\n","       ano  cod_municipio_6dig doenca nome_municipio  casos_notificados\n","7     2002              260030  lepto      AGRESTINA                  0\n","1302  2003              260030  lepto      AGRESTINA                  2\n","2597  2004              260030  lepto      AGRESTINA                  0\n","3892  2005              260030  lepto      AGRESTINA                  2\n","5187  2006              260030  lepto      AGRESTINA                  1\n"]}]},{"cell_type":"code","source":["# Carregar a base socioeconômica para obter a população anual\n","try:\n","    df_socioeconomico = pd.read_csv('/content/drive/MyDrive/02 - Economia (UFPE)/2025.1/Tópicos de Macro (Economia do clima)/analise-saneamento-chuva-extrema-pe/build/output/pib_dens_hab_pe_2002_2021.csv')\n","    # Selecionar apenas as colunas que precisamos para a junção\n","    df_populacao = df_socioeconomico[['cod_municipio', 'ano', 'populacao_estimada']].copy()\n","    print(\"Arquivo 'pib_dens_hab_pe_2002_2021.csv' carregado com sucesso.\")\n","except FileNotFoundError:\n","    print(\"ERRO: Arquivo 'pib_dens_hab_pe_2002_2021.csv' não encontrado.\")\n","    # Adicione um 'return' ou 'exit()' aqui.\n","\n","# ---\n","# ETAPA 2: Agregar as Arboviroses\n","# ---\n","print(\"\\nAgregando os casos de Dengue, Chikungunya e Zika em 'Arboviroses'...\")\n","\n","# Lista das doenças que compõem as arboviroses\n","lista_arboviroses = ['dengue', 'chikun', 'zika']\n","\n","# Filtrar o DataFrame para conter apenas as arboviroses\n","df_arboviroses_raw = df_final_balanceado[df_final_balanceado['doenca'].isin(lista_arboviroses)]\n","\n","# Agrupar por município e ano e somar os casos\n","df_arboviroses_agregado = df_arboviroses_raw.groupby(['cod_municipio_6dig', 'nome_municipio', 'ano'])['casos_notificados'].sum().reset_index()\n","\n","# Adicionar uma coluna para identificar a nova categoria de doença\n","df_arboviroses_agregado['doenca'] = 'arboviroses'\n","\n","# ---\n","# ETAPA 3: Isolar as outras doenças e juntar tudo\n","# ---\n","print(\"Isolando as outras doenças de interesse e combinando os DataFrames...\")\n","\n","# Lista das outras doenças que queremos manter separadas\n","lista_outras_doencas = ['esquisto', 'lepto', 'febretifoide'] # Certifique-se que os nomes estão corretos\n","\n","# Filtrar o DataFrame original para manter apenas essas doenças\n","df_outras_doencas = df_final_balanceado[df_final_balanceado['doenca'].isin(lista_outras_doencas)]\n","\n","# Concatenar o novo DataFrame de arboviroses com o das outras doenças\n","df_saude_processado = pd.concat([df_arboviroses_agregado, df_outras_doencas], ignore_index=True)"],"metadata":{"id":"5sQx0CtLf3jo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---\n","# ETAPA 4: Calcular a Taxa de Incidência por 100 mil Habitantes\n","# ---\n","print(\"Juntando com os dados de população e calculando as taxas de incidência...\")\n","\n","# Renomear a coluna de código do município para o merge\n","df_populacao['cod_municipio_6dig'] = df_populacao['cod_municipio'] // 10\n","\n","# Unir os dados de saúde com os de população\n","df_com_pop = pd.merge(\n","    df_saude_processado,\n","    df_populacao,\n","    on=['cod_municipio_6dig', 'ano'],\n","    how='left' # Usar 'left' para manter todos os registros de saúde\n",")\n","\n","# Calcular a taxa, tratando o caso de população ser zero ou nula\n","df_com_pop['taxa_100mil_hab'] = 0.0\n","# Evitar divisão por zero\n","mask_pop_valida = df_com_pop['populacao_estimada'] > 0\n","df_com_pop.loc[mask_pop_valida, 'taxa_100mil_hab'] = \\\n","    (df_com_pop['casos_notificados'] / df_com_pop['populacao_estimada']) * 100000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIBRPQ8wgkWU","executionInfo":{"status":"ok","timestamp":1754335512774,"user_tz":180,"elapsed":49,"user":{"displayName":"ATHILA DA SILVA GALINDO SANTOS","userId":"11039584104317922331"}},"outputId":"aef5557e-4c6f-44f3-a452-fe4ff5b811e1"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Juntando com os dados de população e calculando as taxas de incidência...\n"]}]},{"cell_type":"code","source":["# ---\n","# ETAPA 5: Pivotar a Tabela para o Formato Final de Análise\n","# ---\n","print(\"Pivotando a tabela para ter uma coluna por doença...\")\n","\n","df_saude_final = df_com_pop.pivot_table(\n","    index=['cod_municipio', 'ano'],\n","    columns='doenca',\n","    values='taxa_100mil_hab'\n",").reset_index()\n","\n","# Limpar os nomes das colunas após o pivot\n","df_saude_final.columns.name = None\n","# Renomear as colunas para um formato mais limpo (ex: 'taxa_arboviroses')\n","df_saude_final.columns = [f'taxa_{col}' if col not in ['cod_municipio', 'ano'] else col for col in df_saude_final.columns]\n","\n","print(\"\\n--- Processamento de Saúde Finalizado! ---\")\n","print(\"Amostra da base de dados de saúde final, pronta para o merge:\")\n","print(df_saude_final.head())\n","\n","df_saude_final.info()\n","\n","df_saude_final.to_parquet('/content/drive/MyDrive/02 - Economia (UFPE)/2025.1/Tópicos de Macro (Economia do clima)/analise-saneamento-chuva-extrema-pe/build/output/doencas_pe_2002_2021.parquet', index=False)"],"metadata":{"id":"Jn0ysBBHi5AF"},"execution_count":null,"outputs":[]}]}